{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from os.path import join,exists,realpath,dirname,basename\n",
    "from os import makedirs,listdir, system\n",
    "import numpy as np, _pickle as cPickle, editdistance, seaborn as sns\n",
    "import matplotlib.pyplot as plt, pandas as pd, itertools, glob, h5py\n",
    "from scipy.stats import entropy\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from IPython.display import display\n",
    "from collections import defaultdict\n",
    "from IPython.display import display\n",
    "from scipy.stats import ranksums\n",
    "import multiprocessing as mp\n",
    "from PIL import Image\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "\n",
    "GPUID = 1\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(GPUID)\n",
    "\n",
    "from scipy import ndimage\n",
    "from six.moves import urllib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import math\n",
    "import sys\n",
    "import scipy.io\n",
    "\n",
    "\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TYPE AND SHAPE OF [  train_total_data ] ARE <class 'numpy.ndarray'> and   (55000, 794)\n",
      " TYPE AND SHAPE OF [   validation_data ] ARE <class 'numpy.ndarray'> and    (5000, 784)\n",
      " TYPE AND SHAPE OF [ validation_labels ] ARE <class 'numpy.ndarray'> and     (5000, 10)\n",
      " TYPE AND SHAPE OF [         test_data ] ARE <class 'numpy.ndarray'> and   (10000, 784)\n",
      " TYPE AND SHAPE OF [       test_labels ] ARE <class 'numpy.ndarray'> and    (10000, 10)\n",
      "WARNING:tensorflow:From <ipython-input-7-1683130eed58>:158: softmax_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.softmax_cross_entropy instead. Note that the order of the logits and labels arguments has been changed.\n",
      "WARNING:tensorflow:From /Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:397: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "WARNING:tensorflow:From /Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:398: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.compute_weighted_loss instead.\n",
      "WARNING:tensorflow:From /Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:146: add_arg_scope.<locals>.func_with_args (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.add_loss instead.\n"
     ]
    }
   ],
   "source": [
    "def CNN(inputs, _is_training=True):\n",
    "    x   = tf.reshape(inputs, [-1, 28, 28, 1])\n",
    "    batch_norm_params = {'is_training': _is_training, 'decay': 0.9, 'updates_collections': None}\n",
    "    net = slim.conv2d(x, 32, [5, 5], padding='SAME'\n",
    "                     , activation_fn       = tf.nn.relu\n",
    "                     , weights_initializer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "                     , normalizer_fn       = slim.batch_norm\n",
    "                     , normalizer_params   = batch_norm_params\n",
    "                     , scope='conv1')\n",
    "    net = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
    "    net = slim.conv2d(net, 64, [5, 5], scope='conv2')\n",
    "    net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
    "    net = slim.flatten(net, scope='flatten3')\n",
    "    net = slim.fully_connected(net, 1024\n",
    "                    , activation_fn       = tf.nn.relu\n",
    "                    , weights_initializer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "                    , normalizer_fn       = slim.batch_norm\n",
    "                    , normalizer_params   = batch_norm_params\n",
    "                    , scope='fc4')\n",
    "    net = slim.dropout(net, keep_prob=0.7, is_training=_is_training, scope='dropout4')  \n",
    "    out = slim.fully_connected(net, 10, activation_fn=None, normalizer_fn=None, scope='fco')\n",
    "    return out\n",
    "\n",
    "\n",
    "# DATA URL\n",
    "SOURCE_URL      = 'http://yann.lecun.com/exdb/mnist/'\n",
    "DATA_DIRECTORY  = \"data\"\n",
    "# PARAMETERS FOR MNIST\n",
    "IMAGE_SIZE      = 28\n",
    "NUM_CHANNELS    = 1\n",
    "PIXEL_DEPTH     = 255\n",
    "NUM_LABELS      = 10\n",
    "VALIDATION_SIZE = 5000  # Size of the validation set.\n",
    "\n",
    "# DOWNLOAD MNIST DATA, IF NECESSARY\n",
    "def maybe_download(filename):\n",
    "    if not tf.gfile.Exists(DATA_DIRECTORY):\n",
    "        tf.gfile.MakeDirs(DATA_DIRECTORY)\n",
    "    filepath = os.path.join(DATA_DIRECTORY, filename)\n",
    "    if not tf.gfile.Exists(filepath):\n",
    "        filepath, _ = urllib.request.urlretrieve(SOURCE_URL + filename, filepath)\n",
    "        with tf.gfile.GFile(filepath) as f:\n",
    "            size = f.size()\n",
    "        print('Successfully downloaded', filename, size, 'bytes.')\n",
    "    return filepath\n",
    "\n",
    "# EXTRACT IMAGES\n",
    "def extract_data(filename, num_images):\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(16)\n",
    "        buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images * NUM_CHANNELS)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "        data = (data - (PIXEL_DEPTH / 2.0)) / PIXEL_DEPTH # -0.5~0.5\n",
    "        data = data.reshape(num_images, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)\n",
    "        data = np.reshape(data, [num_images, -1])\n",
    "    return data # [image index, y, x, channels]\n",
    "\n",
    "# EXTRACT LABELS\n",
    "def extract_labels(filename, num_images):\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1 * num_images)\n",
    "        labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "        num_labels_data = len(labels)\n",
    "        one_hot_encoding = np.zeros((num_labels_data,NUM_LABELS))\n",
    "        one_hot_encoding[np.arange(num_labels_data),labels] = 1\n",
    "        one_hot_encoding = np.reshape(one_hot_encoding, [-1, NUM_LABELS])\n",
    "    return one_hot_encoding\n",
    "\n",
    "# AUGMENT TRAINING DATA\n",
    "def expend_training_data(images, labels):\n",
    "    expanded_images = []\n",
    "    expanded_labels = []\n",
    "    j = 0 # counter\n",
    "    for x, y in zip(images, labels):\n",
    "        j = j+1\n",
    "        # APPEND ORIGINAL DATA\n",
    "        expanded_images.append(x)\n",
    "        expanded_labels.append(y)\n",
    "        # ASSUME MEDIAN COLOR TO BE BACKGROUND COLOR\n",
    "        bg_value = np.median(x) # this is regarded as background's value        \n",
    "        image = np.reshape(x, (-1, 28))\n",
    "\n",
    "        for i in range(4):\n",
    "            # ROTATE IMAGE\n",
    "            angle = np.random.randint(-15,15,1)\n",
    "            new_img = ndimage.rotate(image,angle,reshape=False, cval=bg_value)\n",
    "            # SHIFT IAMGE\n",
    "            shift = np.random.randint(-2, 2, 2)\n",
    "            new_img_ = ndimage.shift(new_img,shift, cval=bg_value)\n",
    "            # ADD TO THE LIST\n",
    "            expanded_images.append(np.reshape(new_img_, 784))\n",
    "            expanded_labels.append(y)\n",
    "    expanded_train_total_data = np.concatenate((expanded_images, expanded_labels), axis=1)\n",
    "    np.random.shuffle(expanded_train_total_data)\n",
    "    return expanded_train_total_data\n",
    "\n",
    "# PREPARE MNIST DATA\n",
    "def prepare_MNIST_data(use_data_augmentation=True):\n",
    "    # Get the data.\n",
    "    train_data_filename = maybe_download('train-images-idx3-ubyte.gz')\n",
    "    train_labels_filename = maybe_download('train-labels-idx1-ubyte.gz')\n",
    "    test_data_filename = maybe_download('t10k-images-idx3-ubyte.gz')\n",
    "    test_labels_filename = maybe_download('t10k-labels-idx1-ubyte.gz')\n",
    "    train_data = extract_data(train_data_filename, 60000)\n",
    "    train_labels = extract_labels(train_labels_filename, 60000)\n",
    "    test_data = extract_data(test_data_filename, 10000)\n",
    "    test_labels = extract_labels(test_labels_filename, 10000)\n",
    "    validation_data = train_data[:VALIDATION_SIZE, :]\n",
    "    validation_labels = train_labels[:VALIDATION_SIZE,:]\n",
    "    train_data = train_data[VALIDATION_SIZE:, :]\n",
    "    train_labels = train_labels[VALIDATION_SIZE:,:]\n",
    "    if use_data_augmentation:\n",
    "        train_total_data = expend_training_data(train_data, train_labels)\n",
    "    else:\n",
    "        train_total_data = np.concatenate((train_data, train_labels), axis=1)\n",
    "    train_size = train_total_data.shape[0]\n",
    "    return train_total_data, train_size, validation_data, validation_labels, test_data, test_labels\n",
    "\n",
    "\n",
    "\n",
    "# CONFIGURATION\n",
    "MODEL_DIRECTORY   = \"model/model.ckpt\"\n",
    "LOGS_DIRECTORY    = \"logs/train\"\n",
    "training_epochs   = 10\n",
    "TRAIN_BATCH_SIZE  = 50\n",
    "display_step      = 500\n",
    "validation_step   = 500\n",
    "TEST_BATCH_SIZE   = 5000    \n",
    "\n",
    "\n",
    "# PREPARE MNIST DATA\n",
    "batch_size = TRAIN_BATCH_SIZE # BATCH SIZE (50)\n",
    "num_labels = NUM_LABELS       # NUMBER OF LABELS (10)\n",
    "train_total_data, train_size, validation_data, validation_labels \\\n",
    "    , test_data, test_labels = prepare_MNIST_data(False)\n",
    "# PRINT FUNCTION\n",
    "def print_np(x, str):\n",
    "    print (\" TYPE AND SHAPE OF [%18s ] ARE %s and %14s\" \n",
    "           % (str, type(x), x.shape,))\n",
    "print_np(train_total_data, 'train_total_data')\n",
    "print_np(validation_data, 'validation_data')\n",
    "print_np(validation_labels, 'validation_labels')\n",
    "print_np(test_data, 'test_data')\n",
    "print_np(test_labels, 'test_labels')\n",
    "################################################################################\n",
    "\n",
    "\n",
    "\n",
    "# DEFINE MODEL\n",
    "# PLACEHOLDERS\n",
    "x  = tf.placeholder(tf.float32, [None, 784])\n",
    "y_ = tf.placeholder(tf.float32, [None, 10]) #answer\n",
    "is_training = tf.placeholder(tf.bool, name='MODE')\n",
    "# CONVOLUTIONAL NEURAL NETWORK MODEL \n",
    "y = CNN(x, is_training)\n",
    "# DEFINE LOSS\n",
    "with tf.name_scope(\"LOSS\"):\n",
    "    loss = slim.losses.softmax_cross_entropy(y, y_)\n",
    "# DEFINE ACCURACY\n",
    "with tf.name_scope(\"ACC\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rundir = '../log_gan_mlp'\n",
    "samples = []\n",
    "for i in range(100):\n",
    "#     print(i)\n",
    "    scorefile = join(rundir, 'epoch_{}.score'.format(i))\n",
    "    if not exists(scorefile):   \n",
    "        datafile = join(rundir, 'epoch_{}.pkl'.format(i))\n",
    "        if not exists(datafile):\n",
    "            break\n",
    "        with open(datafile, 'rb') as f:\n",
    "            sample = cPickle.load(f)\n",
    "            samples.append(sample)\n",
    "samples = np.array(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/model.ckpt\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to get matching files on model/model.ckpt: Not found: model; No such file or directory\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2', defined at:\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-179830fc333c>\", line 5, in <module>\n    saver = tf.train.Saver()\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1293, in __init__\n    self.build()\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1302, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1339, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 796, in _build_internal\n    restore_sequentially, reshape)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 449, in _AddRestoreOps\n    restore_sequentially)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 847, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1030, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to get matching files on model/model.ckpt: Not found: model; No such file or directory\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda/envs/ml/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ml/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ml/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to get matching files on model/model.ckpt: Not found: model; No such file or directory\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-179830fc333c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODEL_DIRECTORY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ml/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1753\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1754\u001b[0m       sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1755\u001b[0;31m                {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1756\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1757\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ml/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ml/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ml/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ml/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to get matching files on model/model.ckpt: Not found: model; No such file or directory\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2', defined at:\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-179830fc333c>\", line 5, in <module>\n    saver = tf.train.Saver()\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1293, in __init__\n    self.build()\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1302, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1339, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 796, in _build_internal\n    restore_sequentially, reshape)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 449, in _AddRestoreOps\n    restore_sequentially)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 847, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1030, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to get matching files on model/model.ckpt: Not found: model; No such file or directory\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "MODEL_DIRECTORY   = \"model/model.ckpt\"\n",
    "# RESTORE SAVED NETWORK\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.2\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer(), feed_dict={is_training: False})\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / np.expand_dims(e_x.sum(axis=1), axis=1)   # only difference\n",
    "\n",
    "\n",
    "saver.restore(sess, MODEL_DIRECTORY)\n",
    "\n",
    "\n",
    "# # folders for generated images\n",
    "# result_folder = './ali_results/'\n",
    "\n",
    "# icp = []\n",
    "# for k in range(50):\n",
    "#     k = k + 1\n",
    "#     # result_folder = '../GAN/ali_bigan/ali_shell_results/'\n",
    "#     # mat = scipy.io.loadmat(result_folder+ '2_2_2_256_256_1024.mat' )\n",
    "#     mat = scipy.io.loadmat(result_folder+ '{}.mat'.format(str(k).zfill(3)))\n",
    "#     test_data  = mat['images']\n",
    "#     #  pdb.set_trace()\n",
    "#     # COMPUTE ACCURACY FOR TEST DATA\n",
    "#     batch_size = 100\n",
    "#     test_size   = test_data.shape[0]\n",
    "#     total_batch = int(test_size / batch_size)\n",
    "#     acc_buffer  = []\n",
    "#     preds = []\n",
    "#     for i in range(total_batch):\n",
    "#         offset = (i * batch_size) % (test_size)\n",
    "#         batch_xs = test_data[offset:(offset + batch_size), :]\n",
    "#         y_final = sess.run(y, feed_dict={x: batch_xs, is_training: False})\n",
    "#         pred_softmax = softmax(y_final)\n",
    "#         preds.append(pred_softmax)\n",
    "\n",
    "\n",
    "#     preds = np.concatenate(preds, 0)\n",
    "#     scores = []\n",
    "#     splits = 10\n",
    "#     for i in range(splits):\n",
    "#       part = preds[(i * preds.shape[0] // splits):((i + 1) * preds.shape[0] // splits), :]\n",
    "#       kl = part * (np.log(part) - np.log(np.expand_dims(np.mean(part, 0), 0)))\n",
    "#       kl = np.mean(np.sum(kl, 1))\n",
    "#       scores.append(np.exp(kl))\n",
    "\n",
    "#     icp.append((np.mean(scores) , np.std(scores)))\n",
    "#     print(\"Inception score is: %.4f, %.4f\" % (np.mean(scores) , np.std(scores)))\n",
    "\n",
    "# scipy.io.savemat('ali_inception_50.mat', mdict={'icp': icp})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
